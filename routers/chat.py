from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
import sys
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.openai_service import OpenAIService
from config import settings

router = APIRouter()

# Pydantic ëª¨ë¸ ì •ì˜
class ChatMessage(BaseModel):
    message: str = Field(..., description="ì‚¬ìš©ì ë©”ì‹œì§€", min_length=1, max_length=4000)
    model: Optional[str] = Field(default=settings.DEFAULT_MODEL, description="ì‚¬ìš©í•  GPT ëª¨ë¸")
    max_tokens: Optional[int] = Field(default=settings.MAX_TOKENS, description="ìµœëŒ€ í† í° ìˆ˜", ge=1, le=8000)
    temperature: Optional[float] = Field(default=settings.TEMPERATURE, description="ì˜¨ë„ ì„¤ì •", ge=0.0, le=2.0)

class ConversationMessage(BaseModel):
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í•  (user, assistant, system)")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©", min_length=1, max_length=4000)

class ConversationRequest(BaseModel):
    messages: List[ConversationMessage] = Field(..., description="ëŒ€í™” íˆìŠ¤í† ë¦¬", min_items=1)
    model: Optional[str] = Field(default=settings.DEFAULT_MODEL, description="ì‚¬ìš©í•  GPT ëª¨ë¸")
    max_tokens: Optional[int] = Field(default=settings.MAX_TOKENS, description="ìµœëŒ€ í† í° ìˆ˜", ge=1, le=8000)
    temperature: Optional[float] = Field(default=settings.TEMPERATURE, description="ì˜¨ë„ ì„¤ì •", ge=0.0, le=2.0)

class ChatResponse(BaseModel):
    success: bool
    data: Dict[str, Any]
    timestamp: str

# OpenAI ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
openai_service = OpenAIService()

@router.post("/message", response_model=ChatResponse)
async def chat_message(request: ChatMessage):
    """
    ChatGPTì™€ ë‹¨ì¼ ë©”ì‹œì§€ë¡œ ëŒ€í™”
    
    - **message**: ì‚¬ìš©ì ë©”ì‹œì§€ (í•„ìˆ˜)
    - **model**: ì‚¬ìš©í•  GPT ëª¨ë¸ (ê¸°ë³¸ê°’: gpt-4o)
    - **max_tokens**: ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ê°’: 4000)
    - **temperature**: ì˜¨ë„ ì„¤ì • (ê¸°ë³¸ê°’: 0.7)
    """
    try:
        print(f"ğŸ“¨ ë°›ì€ ë©”ì‹œì§€: {request.message}")
        print(f"ğŸ¤– ì‚¬ìš©í•  ëª¨ë¸: {request.model}")
        
        # ChatGPT API í˜¸ì¶œ
        response = await openai_service.chat_with_gpt(
            message=request.message,
            model=request.model,
            max_tokens=request.max_tokens,
            temperature=request.temperature
        )
        
        print("âœ… ChatGPT ì‘ë‹µ ì„±ê³µ")
        
        return ChatResponse(
            success=True,
            data={
                "message": response["message"],
                "model": response["model"],
                "usage": response["usage"],
                "timestamp": datetime.now().isoformat()
            },
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as error:
        print(f"âŒ ChatGPT API ì˜¤ë¥˜: {error}")
        
        # OpenAI API ì˜¤ë¥˜ ì²˜ë¦¬
        if "insufficient_quota" in str(error).lower():
            raise HTTPException(
                status_code=402,
                detail="API í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. OpenAI API í• ë‹¹ëŸ‰ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        
        if "invalid_api_key" in str(error).lower():
            raise HTTPException(
                status_code=401,
                detail="ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        
        if "rate_limit_exceeded" in str(error).lower():
            raise HTTPException(
                status_code=429,
                detail="API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        
        # ê¸°íƒ€ ì˜¤ë¥˜
        raise HTTPException(
            status_code=500,
            detail=f"ChatGPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(error)}"
        )

@router.post("/conversation", response_model=ChatResponse)
async def chat_conversation(request: ConversationRequest):
    """
    ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ í•¨ê»˜ ChatGPTì™€ ëŒ€í™”
    
    - **messages**: ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°°ì—´ (í•„ìˆ˜)
    - **model**: ì‚¬ìš©í•  GPT ëª¨ë¸ (ê¸°ë³¸ê°’: gpt-4o)
    - **max_tokens**: ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ê°’: 4000)
    - **temperature**: ì˜¨ë„ ì„¤ì • (ê¸°ë³¸ê°’: 0.7)
    """
    try:
        print(f"ğŸ“¨ ë°›ì€ ëŒ€í™”: {len(request.messages)}ê°œ ë©”ì‹œì§€")
        print(f"ğŸ¤– ì‚¬ìš©í•  ëª¨ë¸: {request.model}")
        
        # ë©”ì‹œì§€ í˜•ì‹ ê²€ì¦
        for msg in request.messages:
            if msg.role not in ["user", "assistant", "system"]:
                raise HTTPException(
                    status_code=400,
                    detail="ë©”ì‹œì§€ ì—­í• ì€ 'user', 'assistant', 'system' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤."
                )
        
        # ChatGPT API í˜¸ì¶œ (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
        response = await openai_service.chat_with_history(
            messages=[{"role": msg.role, "content": msg.content} for msg in request.messages],
            model=request.model,
            max_tokens=request.max_tokens,
            temperature=request.temperature
        )
        
        print("âœ… ChatGPT ì‘ë‹µ ì„±ê³µ")
        
        return ChatResponse(
            success=True,
            data={
                "message": response["message"],
                "model": response["model"],
                "usage": response["usage"],
                "timestamp": datetime.now().isoformat()
            },
            timestamp=datetime.now().isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as error:
        print(f"âŒ ChatGPT API ì˜¤ë¥˜: {error}")
        
        # OpenAI API ì˜¤ë¥˜ ì²˜ë¦¬
        if "insufficient_quota" in str(error).lower():
            raise HTTPException(
                status_code=402,
                detail="API í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. OpenAI API í• ë‹¹ëŸ‰ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        
        if "invalid_api_key" in str(error).lower():
            raise HTTPException(
                status_code=401,
                detail="ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        
        if "rate_limit_exceeded" in str(error).lower():
            raise HTTPException(
                status_code=429,
                detail="API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        
        # ê¸°íƒ€ ì˜¤ë¥˜
        raise HTTPException(
            status_code=500,
            detail=f"ChatGPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(error)}"
        )

@router.get("/models", response_model=ChatResponse)
async def get_available_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ GPT ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    """
    try:
        print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘...")
        
        models = await openai_service.get_available_models()
        
        print(f"âœ… ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {len(models)}ê°œ ëª¨ë¸")
        
        return ChatResponse(
            success=True,
            data={
                "models": models,
                "timestamp": datetime.now().isoformat()
            },
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as error:
        print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {error}")
        raise HTTPException(
            status_code=500,
            detail=f"ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(error)}"
        )
